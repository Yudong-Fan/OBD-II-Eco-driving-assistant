{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_shuffled_v2.csv')\n",
    "test = pd.read_csv('./test_shuffled_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test/train for train data\n",
    "X = train.iloc[:, :-1]\n",
    "y = train['FUEL_CONSUMPTION']\n",
    "\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test['FUEL_CONSUMPTION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm = MinMaxScaler().fit(train.iloc[:, :-1])\n",
    "X = norm.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "X_test = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression as base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE 5.217594647364855\n"
     ]
    }
   ],
   "source": [
    "# linear regression as base line\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_valid)\n",
    "print(\"Linear Regression RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE 7.860535820020106\n"
     ]
    }
   ],
   "source": [
    "# base line test set result\n",
    "y_pred = linear.predict(X_test)\n",
    "print(\"Linear Regression RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & pipeline initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ML models\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2, weights='distance')\n",
    "\n",
    "sgd = SGDRegressor(alpha=0.01, early_stopping=True, epsilon=0.19, l1_ratio=0.98,\n",
    "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
    "             penalty='elasticnet', random_state=42, warm_start=True)\n",
    "\n",
    "svr = SVR(C=4.5, cache_size=1600, coef0=0.6, epsilon=0.9, gamma=0.99, kernel='poly')\n",
    "\n",
    "linear_svr = LinearSVR(C=292, dual=False, epsilon=0.06, loss='squared_epsilon_insensitive',\n",
    "          random_state=42)\n",
    "            \n",
    "dt = DecisionTreeRegressor(criterion='friedman_mse', max_depth=30,\n",
    "                      min_samples_split=12, random_state=42, splitter='random')\n",
    "\n",
    "et = ExtraTreesRegressor(criterion='friedman_mse', max_depth=67, max_features=0.73,\n",
    "                    min_samples_split=4, n_estimators=600, random_state=42)\n",
    "                      \n",
    "rf = RandomForestRegressor(bootstrap=False, criterion='poisson', max_depth=74,\n",
    "                      max_features=0.3, min_samples_split=3, n_estimators=500,\n",
    "                      random_state=42, warm_start=True)\n",
    "\n",
    "nn = MLPRegressor(alpha=0.1111, early_stopping=True,\n",
    "             hidden_layer_sizes=(10, 70, 25), max_iter=15000,\n",
    "             n_iter_no_change=32, random_state=42, solver='lbfgs')\n",
    "\n",
    "ada = AdaBoostRegressor(base_estimator=dt,\n",
    "                  learning_rate=0.36, loss='exponential', n_estimators=400,\n",
    "                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    # # KNN\n",
    "    # knn.fit(X_train, y_train)\n",
    "    # y_pred = knn.predict(X_valid)\n",
    "    # print(\"KNN RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"KNN MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "    \n",
    "    # # SGD\n",
    "    # sgd.fit(X_train, y_train)\n",
    "    # y_pred = sgd.predict(X_valid)\n",
    "    # print(\"SGD RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"SGD MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # # SVR\n",
    "    # svr.fit(X_train, y_train)\n",
    "    # y_pred = svr.predict(X_valid)\n",
    "    # print(\"SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"SVR MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # # Linear SVR\n",
    "    # linear_svr.fit(X_train, y_train)\n",
    "    # y_pred = linear_svr.predict(X_valid)\n",
    "    # print(\"Linear SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"Linear SVR MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # # et\n",
    "    # et.fit(X_train, y_train)\n",
    "    # y_pred = et.predict(X_valid)\n",
    "    # print(\"Extra Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"KExtra TreeNN MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # # Decision Tree\n",
    "    # dt.fit(X_train, y_train)\n",
    "    # y_pred = dt.predict(X_valid)\n",
    "    # print(\"Decision Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"Decision Tree MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # # Random Forest\n",
    "    # rf.fit(X_train, y_train)\n",
    "    # y_pred = rf.predict(X_valid)\n",
    "    # print(\"Random Forest RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"Random Forest MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "\n",
    "    # NN\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred = nn.predict(X_valid)\n",
    "    print(\"Neural Network RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    print(\"Neural Network MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n",
    "    \n",
    "    # # Adaboost\n",
    "    # ada.fit(X_train, y_train)\n",
    "    # y_pred = ada.predict(X_valid)\n",
    "    # print(\"Adaboost RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    # print(\"Adaboost MAPE\", metrics.mean_absolute_percentage_error(y_true=y_valid, y_pred= y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_result(X_test, y_test):\n",
    "\n",
    "    # # KNN\n",
    "    # y_pred = knn.predict(X_test)\n",
    "    # print(\"KNN RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"KNN MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # SGD\n",
    "    # y_pred = sgd.predict(X_test)\n",
    "    # print(\"SGD RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"SGD MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # SVR\n",
    "    # y_pred = svr.predict(X_test)\n",
    "    # print(\"SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"SVR MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # Linear SVR\n",
    "    # y_pred = linear_svr.predict(X_test)\n",
    "    # print(\"Linear SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"Linear SVR MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # Extra Tree\n",
    "    # y_pred = et.predict(X_test)\n",
    "    # print(\"Extra Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"Extra Tree MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # Decision Tree\n",
    "    # y_pred = dt.predict(X_test)\n",
    "    # print(\"Decision Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"Decision Tree MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # Random Forest\n",
    "    # y_pred = rf.predict(X_test)\n",
    "    # print(\"Random Forest RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"Random Forest MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # NN\n",
    "    y_pred = nn.predict(X_test)\n",
    "    print(\"Neural Network RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    print(\"Neural Network MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n",
    "\n",
    "    # # Adaboost\n",
    "    # y_pred = ada.predict(X_test)\n",
    "    # print(\"Adaboost RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "    # print(\"Adaboost MAPE\", metrics.mean_absolute_percentage_error(y_true=y_test, y_pred= y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_fold = 5\n",
    "# folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cv_classical_models(X, y, model):\n",
    "    \n",
    "#     RMSE_scores = []\n",
    "#     MAE_scores = []\n",
    "#     R2_scores = []\n",
    "#     AR2_scores = []\n",
    "    \n",
    "#     for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "#         print('Fold', fold_n, 'started at', time.ctime())\n",
    "#         regr = 0\n",
    "#         X_train, X_valid = X[train_index], X[valid_index]\n",
    "#         y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "#         if model == 'ADA':\n",
    "#             regr = ada\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'SVR':\n",
    "#             regr = svr\n",
    "#             regr.fit(X_train, y_train)\n",
    "        \n",
    "#         if model == 'RF':\n",
    "#             regr = rf\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'DT':\n",
    "#             regr = dt\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'NN':\n",
    "#             regr = nn\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'KNN':\n",
    "#             regr = knn\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'SGD':\n",
    "#             regr = sgd\n",
    "#             regr.fit(X_train, y_train)\n",
    "        \n",
    "#         if model == 'Linear SVR':\n",
    "#             regr = linear_svr\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'ET':\n",
    "#             regr = et\n",
    "#             regr.fit(X_train, y_train)      \n",
    "        \n",
    "#         y_pred_valid = regr.predict(X_valid).reshape(-1,)\n",
    "#         RMSE_score = np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred_valid))\n",
    "#         MAE_score = mean_absolute_error(y_valid,y_pred_valid)\n",
    "#         R2_score = r2_score(y_valid, y_pred_valid)\n",
    "#         RMSE_scores.append(RMSE_score)\n",
    "#         MAE_scores.append(MAE_score)\n",
    "#         R2_scores.append(R2_score)\n",
    "\n",
    "#         n = X.shape[0]\n",
    "#         k = X.shape[1]\n",
    "#         AR2_score = 1-((1-R2_score)*(n-1)/(n-k-1))\n",
    "#         AR2_scores.append(AR2_score)\n",
    "\n",
    "#     print(model,' -- CV RMSE mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(RMSE_scores), np.std(RMSE_scores)))\n",
    "#     print(model,' -- CV MAE mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(MAE_scores), np.std(MAE_scores)))\n",
    "#     print(model,' -- CV R2 mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(R2_scores), np.std(R2_scores)))\n",
    "#     print(model,' -- CV Adjusted R2 mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(AR2_scores), np.std(AR2_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_classical_models(X, y, 'KNN')\n",
    "# cv_classical_models(X, y, 'Linear SVR')\n",
    "# cv_classical_models(X, y, 'SVR')\n",
    "# cv_classical_models(X, y, 'SGD')\n",
    "# cv_classical_models(X, y, 'DT')\n",
    "# cv_classical_models(X, y, 'ET')\n",
    "# cv_classical_models(X, y, 'RF')\n",
    "# cv_classical_models(X, y, 'NN')\n",
    "# cv_classical_models(X, y, 'ADA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network RMSE 0.9675666332012647\n",
      "Neural Network MAPE 0.0024846723022076997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\night\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 44 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   SPEED                                 10000 non-null  float64\n",
      " 1   MAF                                   10000 non-null  float64\n",
      " 2   ENGINE_RPM                            10000 non-null  float64\n",
      " 3   THROTTLE_POS                          10000 non-null  float64\n",
      " 4   INTAKE_MANIFOLD_PRESSURE              10000 non-null  float64\n",
      " 5   ENGINE_LOAD                           10000 non-null  float64\n",
      " 6   FUEL_RATE                             10000 non-null  float64\n",
      " 7   FUEL_RATE_SQRT                        10000 non-null  float64\n",
      " 8   FUEL_RATE_PWR_2                       10000 non-null  float64\n",
      " 9   FUEL_RATE_PWR_3                       10000 non-null  float64\n",
      " 10  INTAKE_MANIFOLD_PRESSURE_SQRT         10000 non-null  float64\n",
      " 11  INTAKE_MANIFOLD_PRESSURE_PWR_2        10000 non-null  float64\n",
      " 12  INTAKE_MANIFOLD_PRESSURE_PWR_3        10000 non-null  float64\n",
      " 13  MAF_SQRT                              10000 non-null  float64\n",
      " 14  MAF_PWR_2                             10000 non-null  float64\n",
      " 15  MAF_PWR_3                             10000 non-null  float64\n",
      " 16  ENGINE_RPM_SQRT                       10000 non-null  float64\n",
      " 17  ENGINE_RPM_PWR_2                      10000 non-null  float64\n",
      " 18  ENGINE_RPM_PWR_3                      10000 non-null  float64\n",
      " 19  SPEED_SQRT                            10000 non-null  float64\n",
      " 20  SPEED_PWR_2                           10000 non-null  float64\n",
      " 21  SPEED_PWR_3                           10000 non-null  float64\n",
      " 22  ENGINE_LOAD_SQRT                      10000 non-null  float64\n",
      " 23  ENGINE_LOAD_PWR_2                     10000 non-null  float64\n",
      " 24  ENGINE_LOAD_PWR_3                     10000 non-null  float64\n",
      " 25  THROTTLE_POS_SQRT                     10000 non-null  float64\n",
      " 26  THROTTLE_POS_PWR_2                    10000 non-null  float64\n",
      " 27  THROTTLE_POS_PWR_3                    10000 non-null  float64\n",
      " 28  SPEED_X_ENGINE_LOAD                   10000 non-null  float64\n",
      " 29  SPEED_X_MAF                           10000 non-null  float64\n",
      " 30  SPEED_X_FUEL_RATE                     10000 non-null  float64\n",
      " 31  SPEED_X_ENGINE_RPM                    10000 non-null  float64\n",
      " 32  SPEED_X_THROTTLE_POS                  10000 non-null  float64\n",
      " 33  SPEED_X_INTAKE_MANIFOLD_PRESSURE      10000 non-null  float64\n",
      " 34  MAF_X_ENGINE_LOAD                     10000 non-null  float64\n",
      " 35  MAF_X_FUEL_RATE                       10000 non-null  float64\n",
      " 36  MAF_X_ENGINE_RPM                      10000 non-null  float64\n",
      " 37  MAF_X_THROTTLE_POS                    10000 non-null  float64\n",
      " 38  MAF_X_INTAKE_MANIFOLD_PRESSURE        10000 non-null  float64\n",
      " 39  FUEL_RATE_X_ENGINE_LOAD               10000 non-null  float64\n",
      " 40  FUEL_RATE_X_ENGINE_RPM                10000 non-null  float64\n",
      " 41  FUEL_RATE_X_THROTTLE_POS              10000 non-null  float64\n",
      " 42  FUEL_RATE_X_INTAKE_MANIFOLD_PRESSURE  10000 non-null  float64\n",
      " 43  FUEL_CONSUMPTION                      10000 non-null  float64\n",
      "dtypes: float64(44)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network RMSE 0.2991187746972061\n",
      "Neural Network MAPE 0.002367546588646389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KNN RMSE 4.969371400946747\\nKNN MAPE 0.07629307893785157\\nSGD RMSE 10.641319502256032\\nSGD MAPE 0.5189861427956324\\nSVR RMSE 9.131021569061796\\nSVR MAPE 0.10737832794044584\\nLinear SVR RMSE 6.613063495214109\\nLinear SVR MAPE 0.43949283361762104\\nExtra Tree RMSE 2.387114947752746\\nExtra Tree MAPE 0.01057194277783781\\nDecision Tree RMSE 3.2101628270970233\\nDecision Tree MAPE 0.05234468768972168\\nRandom Forest RMSE 3.416570641423174\\nRandom Forest MAPE 0.2625709069635105\\nNeural Network RMSE 0.143510272403907\\nNeural Network MAPE 0.0068828416011658435\\nAdaboost RMSE 1.6083412524203518\\nAdaboost MAPE 0.01636706686532803\\nGradient boosting RMSE 2.0069944092547836\\nGradient boosting MAPE 0.0370013317164879'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_result(X_test, y_test)\n",
    "\n",
    "'''KNN RMSE 4.969371400946747\n",
    "KNN MAPE 0.07629307893785157\n",
    "SGD RMSE 10.641319502256032\n",
    "SGD MAPE 0.5189861427956324\n",
    "SVR RMSE 9.131021569061796\n",
    "SVR MAPE 0.10737832794044584\n",
    "Linear SVR RMSE 6.613063495214109\n",
    "Linear SVR MAPE 0.43949283361762104\n",
    "Extra Tree RMSE 2.387114947752746\n",
    "Extra Tree MAPE 0.01057194277783781\n",
    "Decision Tree RMSE 3.2101628270970233\n",
    "Decision Tree MAPE 0.05234468768972168\n",
    "Random Forest RMSE 3.416570641423174\n",
    "Random Forest MAPE 0.2625709069635105\n",
    "Neural Network RMSE 0.143510272403907\n",
    "Neural Network MAPE 0.0068828416011658435\n",
    "Adaboost RMSE 1.6083412524203518\n",
    "Adaboost MAPE 0.01636706686532803\n",
    "Gradient boosting RMSE 2.0069944092547836\n",
    "Gradient boosting MAPE 0.0370013317164879'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUEL_RATE_SQRT 1.479 +/- 0.220\n",
      "MAF_SQRT 1.356 +/- 0.192\n",
      "SPEED_SQRT 1.002 +/- 0.028\n",
      "SPEED    0.563 +/- 0.039\n",
      "SPEED_X_THROTTLE_POS 0.167 +/- 0.023\n",
      "SPEED_X_ENGINE_RPM 0.156 +/- 0.027\n",
      "SPEED_X_ENGINE_LOAD 0.148 +/- 0.028\n",
      "SPEED_X_INTAKE_MANIFOLD_PRESSURE 0.094 +/- 0.011\n",
      "SPEED_PWR_2 0.070 +/- 0.016\n",
      "SPEED_X_MAF 0.030 +/- 0.012\n",
      "SPEED_X_FUEL_RATE 0.022 +/- 0.010\n",
      "FUEL_RATE 0.017 +/- 0.002\n",
      "MAF      0.016 +/- 0.002\n",
      "ENGINE_RPM 0.009 +/- 0.002\n",
      "FUEL_RATE_PWR_3 0.001 +/- 0.000\n",
      "MAF_X_ENGINE_RPM 0.000 +/- 0.000\n",
      "ENGINE_LOAD_PWR_3 0.000 +/- 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FUEL_RATE_SQRT 1.462 +/- 0.233\\nMAF_SQRT 1.341 +/- 0.202\\nSPEED_SQRT 1.001 +/- 0.032\\nSPEED    0.553 +/- 0.033\\nSPEED_X_THROTTLE_POS 0.162 +/- 0.023\\nSPEED_X_ENGINE_RPM 0.150 +/- 0.026\\nSPEED_X_ENGINE_LOAD 0.141 +/- 0.026\\nSPEED_X_INTAKE_MANIFOLD_PRESSURE 0.092 +/- 0.011\\nSPEED_PWR_2 0.068 +/- 0.015\\nSPEED_X_MAF 0.030 +/- 0.013\\nSPEED_X_FUEL_RATE 0.023 +/- 0.011\\nFUEL_RATE 0.017 +/- 0.002\\nMAF      0.016 +/- 0.002\\nENGINE_RPM 0.009 +/- 0.002\\nFUEL_RATE_PWR_3 0.001 +/- 0.000\\nMAF_X_ENGINE_RPM 0.000 +/- 0.000\\nENGINE_LOAD_PWR_3 0.000 +/- 0.000'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r = permutation_importance(nn, X_valid, y_valid,\n",
    "                            n_repeats=30,\n",
    "                            random_state=42)\n",
    "\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{train.columns[i]:<8} \"\n",
    "            f\"{r.importances_mean[i]:.3f}\"\n",
    "            f\" +/- {r.importances_std[i]:.3f}\")\n",
    "\n",
    "'''FUEL_RATE_SQRT 1.462 +/- 0.233\n",
    "MAF_SQRT 1.341 +/- 0.202\n",
    "SPEED_SQRT 1.001 +/- 0.032\n",
    "SPEED    0.553 +/- 0.033\n",
    "SPEED_X_THROTTLE_POS 0.162 +/- 0.023\n",
    "SPEED_X_ENGINE_RPM 0.150 +/- 0.026\n",
    "SPEED_X_ENGINE_LOAD 0.141 +/- 0.026\n",
    "SPEED_X_INTAKE_MANIFOLD_PRESSURE 0.092 +/- 0.011\n",
    "SPEED_PWR_2 0.068 +/- 0.015\n",
    "SPEED_X_MAF 0.030 +/- 0.013\n",
    "SPEED_X_FUEL_RATE 0.023 +/- 0.011\n",
    "FUEL_RATE 0.017 +/- 0.002\n",
    "MAF      0.016 +/- 0.002\n",
    "ENGINE_RPM 0.009 +/- 0.002\n",
    "FUEL_RATE_PWR_3 0.001 +/- 0.000\n",
    "MAF_X_ENGINE_RPM 0.000 +/- 0.000\n",
    "ENGINE_LOAD_PWR_3 0.000 +/- 0.000'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tuning efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest estimator found:\\n KNeighborsRegressor(n_neighbors=2, weights='distance')\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_neighbors = [x for x in range(1, 100)]\n",
    "# weights = ['uniform', 'distance']\n",
    "# algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "# parameter_space = {\n",
    "#     'n_neighbors' : n_neighbors,\n",
    "#     'weights' : weights,\n",
    "#     'algorithm' : algorithm\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(KNeighborsRegressor(), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''\n",
    "Best estimator found:\n",
    " KNeighborsRegressor(n_neighbors=2, weights='distance')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest estimator found:\\n SVR(C=4.5, cache_size=1600, coef0=0.6, epsilon=0.9, gamma=0.99, kernel='poly')\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# gamma = [x * 0.01 for x in range(1, 100)]\n",
    "# coef0 = [x * 0.01 for x in range(1, 100)]\n",
    "# epsilon = [x * 0.01 for x in range(1, 100)]\n",
    "# C = [x * 0.1 for x in range(1, 50)]\n",
    "# cache_size = [x for x in range(200, 2000, 200)]\n",
    "# parameter_space = {\n",
    "#     'kernel' : kernel,\n",
    "#     'gamma' : gamma,\n",
    "#     'coef0' : coef0,\n",
    "#     'epsilon' : epsilon,\n",
    "#     'C' : C,\n",
    "#     'cache_size' : cache_size,\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(SVR(), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''\n",
    "Best estimator found:\n",
    " SVR(C=4.5, cache_size=1600, coef0=0.6, epsilon=0.9, gamma=0.99, kernel='poly')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epsilon = [x * 0.01 for x in range(0, 100)]\n",
    "# C = [x for x in range(100, 1000)]\n",
    "# loss = ['epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "# parameter_space = {\n",
    "#     'epsilon' : epsilon,\n",
    "#     'C' : C,\n",
    "#     'loss' : loss\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(LinearSVR(random_state=42, dual=False), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=5000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "# '''\n",
    "# Best estimator found:\n",
    "#  LinearSVR(C=292, dual=False, epsilon=0.06, loss='squared_epsilon_insensitive',\n",
    "#           random_state=42)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest estimator found:\\n DecisionTreeRegressor(criterion='friedman_mse', max_depth=30,\\n                      min_samples_split=12, random_state=42, splitter='random')\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth = [x for x in range(1, 100)]\n",
    "# min_samples_split = [x for x in range(1, 100)]\n",
    "# min_samples_leaf = [x for x in range(1, 100)]\n",
    "\n",
    "# parameter_space = {\n",
    "#     'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "#     'splitter': ['best', 'random'],\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(DecisionTreeRegressor(random_state=42), parameter_space, n_jobs=4, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''\n",
    "Best estimator found:\n",
    " DecisionTreeRegressor(criterion='friedman_mse', max_depth=30,\n",
    "                      min_samples_split=12, random_state=42, splitter='random')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best estimator found:\\n RandomForestRegressor(bootstrap=False, criterion='poisson', max_depth=74,\\n                      max_features=0.3, min_samples_split=3, n_estimators=500,\\n                      random_state=42, warm_start=True)\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators = [x for x in range(100, 1000, 100)]\n",
    "# max_depth = [x for x in range(1, 100)]\n",
    "# min_samples_split = [x for x in range(1, 20)]\n",
    "# min_samples_leaf = [x for x in range(1, 20)]\n",
    "# max_features = [x * 0.01 for x in range(1, 100)]\n",
    "# bootstrap = [True, False]\n",
    "# warm_start = [True, False]\n",
    "\n",
    "# parameter_space = {\n",
    "#     'n_estimators' : n_estimators,\n",
    "#     'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
    "#     'max_features': max_features,\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "#     'bootstrap' : bootstrap,\n",
    "#     'warm_start' : warm_start\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(RandomForestRegressor(random_state=42), parameter_space, n_jobs=8, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''Best estimator found:\n",
    " RandomForestRegressor(bootstrap=False, criterion='poisson', max_depth=74,\n",
    "                      max_features=0.3, min_samples_split=3, n_estimators=500,\n",
    "                      random_state=42, warm_start=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best estimator found:\\n ExtraTreesRegressor(criterion='friedman_mse', max_depth=67, max_features=0.73,\\n                    min_samples_split=4, n_estimators=600, random_state=42)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators = [x for x in range(100, 1000, 100)]\n",
    "# max_depth = [x for x in range(1, 100)]\n",
    "# min_samples_split = [x for x in range(1, 20)]\n",
    "# min_samples_leaf = [x for x in range(1, 20)]\n",
    "# max_features = [x * 0.01 for x in range(1, 100)]\n",
    "# bootstrap = [True, False]\n",
    "# warm_start = [True, False]\n",
    "\n",
    "# parameter_space = {\n",
    "#     'n_estimators' : n_estimators,\n",
    "#     'criterion': ['squared_error', 'absolute_error', 'friedman_mse'],\n",
    "#     'max_features': max_features,\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "#     'bootstrap' : bootstrap,\n",
    "#     'warm_start' : warm_start\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(ExtraTreesRegressor(random_state=42), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''Best estimator found:\n",
    " ExtraTreesRegressor(criterion='friedman_mse', max_depth=67, max_features=0.73,\n",
    "                    min_samples_split=4, n_estimators=600, random_state=42)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best estimator found:\\n AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='friedman_mse',\\n                                                       max_depth=30,\\n                                                       min_samples_split=12,\\n                                                       random_state=42,\\n                                                       splitter='random'),\\n                  learning_rate=0.36, loss='exponential', n_estimators=400,\\n                  random_state=42)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators = [x for x in range(50, 500, 50)]\n",
    "# learning_rate = [x * 0.01 for x in range(1, 100)]\n",
    "# loss = ['linear', 'square', 'exponential']\n",
    "\n",
    "# parameter_space = {\n",
    "#     'n_estimators' : n_estimators,\n",
    "#     'learning_rate' : learning_rate,\n",
    "#     'loss' : loss\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(AdaBoostRegressor(dt, random_state=42), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''Best estimator found:\n",
    " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='friedman_mse',\n",
    "                                                       max_depth=30,\n",
    "                                                       min_samples_split=12,\n",
    "                                                       random_state=42,\n",
    "                                                       splitter='random'),\n",
    "                  learning_rate=0.36, loss='exponential', n_estimators=400,\n",
    "                  random_state=42)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best estimator found:\\n SGDRegressor(alpha=0.01, early_stopping=True, epsilon=0.19, l1_ratio=0.98,\\n             learning_rate='adaptive', loss='squared_epsilon_insensitive',\\n             penalty='elasticnet', random_state=42)\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# penalty = ['l1', 'l2', 'elasticnet']\n",
    "# l1_ratio = [x * 0.01 for x in range(1, 100)]\n",
    "# alpha = [x * 0.01 for x in range(1, 100)]\n",
    "# epsilon = [x * 0.01 for x in range(1, 100)]\n",
    "# loss = ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "# learning_rate = ['constant','adaptive', 'invscaling', 'optimal']\n",
    "\n",
    "# parameter_space = {\n",
    "#     'penalty' : penalty,\n",
    "#     'alpha' : alpha,\n",
    "#     'loss' : loss, \n",
    "#     'l1_ratio' : l1_ratio,\n",
    "#     'epsilon' : epsilon,\n",
    "#     'learning_rate' : learning_rate,\n",
    "\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(SGDRegressor(random_state=42, early_stopping=True), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''Best estimator found:\n",
    " SGDRegressor(alpha=0.01, early_stopping=True, epsilon=0.19, l1_ratio=0.98,\n",
    "             learning_rate='adaptive', loss='squared_epsilon_insensitive',\n",
    "             penalty='elasticnet', random_state=42)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest estimator found:\\nMLPRegressor(alpha=0.1111, early_stopping=True, hidden_layer_sizes=(10, 70, 25),\\n             learning_rate='adaptive', max_iter=15000, n_iter_no_change=32,\\n             solver='lbfgs', random_state=42)\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# layer = [(x, y, z) for x in range(10,50,5) for y in range(10,50,5) for z in range(10,50,5)]\n",
    "# alpha = [x * 0.00001 for x in range(10, 100000, 10)]\n",
    "# max_iter = [x for x in range(1000, 15000, 2000)]\n",
    "# early_stopping = [True]\n",
    "# n_iter_no_change = [32]\n",
    "\n",
    "# parameter_space = {\n",
    "#     'hidden_layer_sizes': layer,\n",
    "#     'activation': ['tanh', 'relu', 'logistic', 'identity'],\n",
    "#     'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "#     'alpha': alpha,\n",
    "#     'learning_rate': ['constant','adaptive', 'invascaling'],\n",
    "#     'max_iter' : max_iter,\n",
    "#     'early_stopping' : early_stopping,\n",
    "#     'n_iter_no_change' : n_iter_no_change,\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(MLPRegressor(random_state=42), parameter_space, n_jobs=12, cv = 3, verbose=2, random_state=42, n_iter=1000)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('Best estimator found:\\n', clf.best_estimator_)\n",
    "\n",
    "'''\n",
    "Best estimator found:\n",
    "MLPRegressor(alpha=0.1111, early_stopping=True, hidden_layer_sizes=(10, 70, 25),\n",
    "             learning_rate='adaptive', max_iter=15000, n_iter_no_change=32,\n",
    "             solver='lbfgs', random_state=42)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take away -> 21th APRIL\n",
    "# tsfresh\n",
    "# autoML\n",
    "# try larger dataset -> eVED\n",
    "# discover & derive new feature -> gear\n",
    "# model comparison -> good to go\n",
    "# naive base line for regression problem -> linear regression \n",
    "# future email also cc -> l.pantiskas@vu.nl\n",
    "# next meeting MAY 2, 10 am\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06e0f87ab8b70c106033d176c4661a31bf024dab1f89ad13f63ade89972f0e9f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
