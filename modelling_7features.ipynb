{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_shuffled_7features.csv')\n",
    "test = pd.read_csv('./test_shuffled_7features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test/train for train data\n",
    "X = train.iloc[:, :-1]\n",
    "y = train['FUEL_CONSUMPTION']\n",
    "\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test['FUEL_CONSUMPTION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize train data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm = MinMaxScaler().fit(train.iloc[:, :-1])\n",
    "X = norm.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test data\n",
    "X_test = norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression as base line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE 11.186266994830012\n"
     ]
    }
   ],
   "source": [
    "# linear regression as base line\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_valid)\n",
    "print(\"Linear Regression RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE 11.186438017490415\n"
     ]
    }
   ],
   "source": [
    "# base line test set result\n",
    "y_pred = linear.predict(X_test)\n",
    "print(\"Linear Regression RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model & pipeline initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ML models\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=1, weights='distance')\n",
    "\n",
    "sgd = SGDRegressor(alpha=5.1145874299878906e-05, average=True,\n",
    "               eta0=1.3342174605223877e-05, l1_ratio=0.3883764520954751,\n",
    "               max_iter=512, penalty='elasticnet', power_t=0.06294035436457378,\n",
    "               random_state=42, tol=4.672384942590959e-05, warm_start=True)\n",
    "\n",
    "svr = SVR(C=3133.304218632794, cache_size=2008.7369791666667,\n",
    "      coef0=0.4057352025775811, epsilon=0.005909999318357989,\n",
    "      gamma=0.0009196972638709646, kernel='poly', tol=0.002555869012110542,\n",
    "      verbose=0)\n",
    "\n",
    "linear_svr = LinearSVR(C=28731.940263285174, dual=False, epsilon=0.7872520084668472,\n",
    "            loss='squared_epsilon_insensitive', random_state=42,\n",
    "            tol=2.2381728154443955e-05)\n",
    "\n",
    "# dt = DecisionTreeRegressor(max_depth=40)\n",
    "dt = DecisionTreeRegressor(criterion='friedman_mse', max_depth=4655,\n",
    "                        min_samples_leaf=5, min_samples_split=12,\n",
    "                        random_state=42)\n",
    "\n",
    "et = ExtraTreesRegressor(criterion='friedman_mse', max_features=0.857137620215694,\n",
    "                      n_estimators=512, n_jobs=1, random_state=42,\n",
    "                      warm_start=True)\n",
    "                      \n",
    "# rf = RandomForestRegressor(n_estimators=600,min_samples_split= 5,min_samples_leaf=2,max_features='auto',max_depth=20,bootstrap=False, random_state=0, n_jobs=-1)\n",
    "rf = RandomForestRegressor(bootstrap=False, max_features=0.22177348265923788,\n",
    "                        min_samples_split=10, n_estimators=512, n_jobs=1,\n",
    "                        random_state=42)\n",
    "\n",
    "nn = MLPRegressor(alpha=0.1111, early_stopping=True, hidden_layer_sizes=(10, 70, 25),\n",
    "             learning_rate='adaptive', max_iter=15000, n_iter_no_change=32,\n",
    "             solver='lbfgs', random_state=42)\n",
    "\n",
    "ada = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=9),\n",
    "                    learning_rate=0.39825318885251826, loss='square',\n",
    "                    n_estimators=317, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, X_valid, y_train, y_valid):\n",
    "\n",
    "    # KNN\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_valid)\n",
    "    print(\"KNN RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    \n",
    "    # SGD\n",
    "    sgd.fit(X_train, y_train)\n",
    "    y_pred = sgd.predict(X_valid)\n",
    "    print(\"SGD RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # SVR\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_valid)\n",
    "    print(\"SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # Linear SVR\n",
    "    linear_svr.fit(X_train, y_train)\n",
    "    y_pred = linear_svr.predict(X_valid)\n",
    "    print(\"Linear SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # et\n",
    "    et.fit(X_train, y_train)\n",
    "    y_pred = et.predict(X_valid)\n",
    "    print(\"Extra Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # Decision Tree\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_valid)\n",
    "    print(\"Decision Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_valid)\n",
    "    print(\"Random Forest RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "\n",
    "    # NN\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred = nn.predict(X_valid)\n",
    "    print(\"Neural Network RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n",
    "    \n",
    "    # Adaboost\n",
    "    ada.fit(X_train, y_train)\n",
    "    y_pred = ada.predict(X_valid)\n",
    "    print(\"Adaboost RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_result(X_test, y_test):\n",
    "\n",
    "    # KNN\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"KNN RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # SGD\n",
    "    y_pred = sgd.predict(X_test)\n",
    "    print(\"SGD RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # SVR\n",
    "    y_pred = svr.predict(X_test)\n",
    "    print(\"SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # Linear SVR\n",
    "    y_pred = linear_svr.predict(X_test)\n",
    "    print(\"Linear SVR RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # Extra Tree\n",
    "    y_pred = et.predict(X_test)\n",
    "    print(\"Extra Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # Decision Tree\n",
    "    y_pred = dt.predict(X_test)\n",
    "    print(\"Decision Tree RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # Random Forest\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(\"Random Forest RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # NN\n",
    "    y_pred = nn.predict(X_test)\n",
    "    print(\"Neural Network RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))\n",
    "\n",
    "    # Adaboost\n",
    "    y_pred = ada.predict(X_test)\n",
    "    print(\"Adaboost RMSE\", np.sqrt(metrics.mean_squared_error(y_true=y_test, y_pred= y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_fold = 5\n",
    "# folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cv_classical_models(X, y, model):\n",
    "    \n",
    "#     RMSE_scores = []\n",
    "#     MAE_scores = []\n",
    "#     R2_scores = []\n",
    "#     AR2_scores = []\n",
    "    \n",
    "#     for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "#         print('Fold', fold_n, 'started at', time.ctime())\n",
    "#         regr = 0\n",
    "#         X_train, X_valid = X[train_index], X[valid_index]\n",
    "#         y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "#         if model == 'ADA':\n",
    "#             regr = ada\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'SVR':\n",
    "#             regr = svr\n",
    "#             regr.fit(X_train, y_train)\n",
    "        \n",
    "#         if model == 'RF':\n",
    "#             regr = rf\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'DT':\n",
    "#             regr = dt\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'NN':\n",
    "#             regr = nn\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'KNN':\n",
    "#             regr = knn\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'SGD':\n",
    "#             regr = sgd\n",
    "#             regr.fit(X_train, y_train)\n",
    "        \n",
    "#         if model == 'Linear SVR':\n",
    "#             regr = linear_svr\n",
    "#             regr.fit(X_train, y_train)\n",
    "\n",
    "#         if model == 'ET':\n",
    "#             regr = et\n",
    "#             regr.fit(X_train, y_train)      \n",
    "        \n",
    "#         y_pred_valid = regr.predict(X_valid).reshape(-1,)\n",
    "#         RMSE_score = np.sqrt(metrics.mean_squared_error(y_true=y_valid, y_pred= y_pred_valid))\n",
    "#         MAE_score = mean_absolute_error(y_valid,y_pred_valid)\n",
    "#         R2_score = r2_score(y_valid, y_pred_valid)\n",
    "#         RMSE_scores.append(RMSE_score)\n",
    "#         MAE_scores.append(MAE_score)\n",
    "#         R2_scores.append(R2_score)\n",
    "\n",
    "#         n = X.shape[0]\n",
    "#         k = X.shape[1]\n",
    "#         AR2_score = 1-((1-R2_score)*(n-1)/(n-k-1))\n",
    "#         AR2_scores.append(AR2_score)\n",
    "\n",
    "#     print(model,' -- CV RMSE mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(RMSE_scores), np.std(RMSE_scores)))\n",
    "#     print(model,' -- CV MAE mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(MAE_scores), np.std(MAE_scores)))\n",
    "#     print(model,' -- CV R2 mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(R2_scores), np.std(R2_scores)))\n",
    "#     print(model,' -- CV Adjusted R2 mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(AR2_scores), np.std(AR2_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_classical_models(X, y, 'KNN')\n",
    "# cv_classical_models(X, y, 'Linear SVR')\n",
    "# cv_classical_models(X, y, 'SVR')\n",
    "# cv_classical_models(X, y, 'SGD')\n",
    "# cv_classical_models(X, y, 'DT')\n",
    "# cv_classical_models(X, y, 'ET')\n",
    "# cv_classical_models(X, y, 'RF')\n",
    "# cv_classical_models(X, y, 'NN')\n",
    "# cv_classical_models(X, y, 'ADA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE 8.815757323015635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\night\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1225: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD RMSE 12.218796920565973\n",
      "SVR RMSE 11.747059841253327\n",
      "Linear SVR RMSE 11.211898925931491\n",
      "Extra Tree RMSE 1.5157794179298565\n",
      "Decision Tree RMSE 2.0627827543621287\n",
      "Random Forest RMSE 4.8068407916663825\n",
      "Neural Network RMSE 6.04454723803436\n",
      "Adaboost RMSE 2.295935828260476\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE 8.046013731558524\n",
      "SGD RMSE 12.326752958523212\n",
      "SVR RMSE 11.880209855201374\n",
      "Linear SVR RMSE 11.19949840416876\n",
      "Extra Tree RMSE 1.251918556603486\n",
      "Decision Tree RMSE 2.5990525831430706\n",
      "Random Forest RMSE 3.7343668777795744\n",
      "Neural Network RMSE 5.746746270521942\n",
      "Adaboost RMSE 1.2561150367808531\n"
     ]
    }
   ],
   "source": [
    "test_data_result(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff5e65052372cb4e82f711e1f5e9e3de3e295539c2d5e104c7ef48a12bc602b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
